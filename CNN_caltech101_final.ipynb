{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NCphU_f8Xv4b",
        "outputId": "76b703f1-2421-467f-b721-e1d7e6b617a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.19.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (2.19.0)\n",
            "Collecting tensorflow-keras (from -r requirements.txt (line 17))\n",
            "  Downloading tensorflow_keras-0.1-py3-none-any.whl.metadata (63 bytes)\n",
            "Requirement already satisfied: numpy<2.2,>=1.26 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 25)) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (3.10.0)\n",
            "Requirement already satisfied: tqdm>=4.64 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 33)) (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->-r requirements.txt (line 16)) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->-r requirements.txt (line 25)) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->-r requirements.txt (line 25)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->-r requirements.txt (line 25)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5->-r requirements.txt (line 28)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5->-r requirements.txt (line 28)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5->-r requirements.txt (line 28)) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5->-r requirements.txt (line 28)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5->-r requirements.txt (line 28)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5->-r requirements.txt (line 28)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5->-r requirements.txt (line 28)) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 16)) (0.1.2)\n",
            "Downloading tensorflow_keras-0.1-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: tensorflow-keras\n",
            "Successfully installed tensorflow-keras-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# 업로드된 ZIP 파일 압축 해제\n",
        "with zipfile.ZipFile(\"/content/archive.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")\n",
        "\n",
        "# 압축 해제 결과 확인\n",
        "os.listdir(\"/content/caltech-101\")[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGQvYC8rlLd4",
        "outputId": "98bb8e82-9f69-4508-f0be-862286f1cfb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['octopus', 'platypus', 'dollar_bill', 'dolphin', 'buddha']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "프로그램 파이프라인 개요:\n",
        "    1) 데이터: Kaggle Caltech-101 압축을 해제한 폴더에서 Faces_easy 클래스를 제외한다.\n",
        "       (Caltech-101은 101개 객체 클래스 + background로 구성된 대표적인 분류 데이터셋)\n",
        "    2) 입력: 모든 이미지를 128×128로 리사이즈하고 RGB를 0~1로 정규화한다. (Keras/TensorFlow 권장 전처리)\n",
        "    3) 분할: 전체를 무작위 셔플 후 train/val/test = 8:1:1로 분할한다.\n",
        "    4) 증강: dataset에 수평 뒤집기, 회전, 확대/축소, 대비 변화를 적용한다.\n",
        "       (Keras 이미지 증강 레이어 사용; 추론 시에는 비활성)\n",
        "    5) 탐색: 필요 시 하이퍼파라미터 탐색을 수행한다.\n",
        "       - 구조 탐색: conv_blocks, base_filters 조합\n",
        "       - 세부 탐색: dropout, optimizer, learning rate, epochs 조합\n",
        "       - 조기종료(EarlyStopping)와 Plateau 시 학습률 감소(ReduceLROnPlateau)로 안정화\n",
        "         (val_loss 모니터링, patience 설정)\n",
        "       - 검증 성능(F1 포함)을 기준으로 최적 조합을 선택한다.\n",
        "    6) 최종학습: 선택된 최적 하이퍼파라미터로 train/val 전체를 활용해 다시 학습하고\n",
        "       가중치를 best_model.weights.h5로 저장한다. (가중치 형식)\n",
        "    7) 평가: test 데이터로 예측을 수행하고 confusion_matrix.png와 매크로 F1 점수를 출력한다.\n",
        "\n",
        "파일 구조:\n",
        "    - data_loader.py  : 데이터 로딩/전처리/분할(Faces_easy 제거, 8:1:1, cache/prefetch)\n",
        "    - cnn_model.py    : 모델 빌드/증강/탐색/학습/평가 유틸\n",
        "    - train.py        : 학습 실행 스크립트 (필요 시 --search로 하이퍼파라미터 탐색)\n",
        "    - evaluate.py     : 평가 실행 스크립트 (학습 때의 구조/파라미터를 동일하게 지정해야함)\n",
        "\n",
        "Colab 사용 절차:\n",
        "    1) 로컬에서 Kaggle Caltech-101(archive.zip) 다운로드 후 Colab ‘파일’ 패널로 드래그 (/content 내로)\n",
        "    2) 런타임 유형: GPU(T4) 설정\n",
        "    3) 라이브러리 설치:\n",
        "    !pip install tensorflow tensorflow-datasets tensorflow.keras scikit-learn matplotlib pathlib tqdm\n",
        "    !pip install --upgrade tensorflow\n",
        "    4) 데이터 압축 해제 후 경로 예: /content/caltech-101\n",
        "    5) 학습 실행 예시:\n",
        "       %cd ML_CNN\n",
        "       !python train.py --data-dir /content/caltech-101 --augment\n",
        "       # 하이퍼파라미터 탐색을 켜려면: --search\n",
        "    6) 평가 실행 예시:\n",
        "       !python evaluate.py --data-dir /content/caltech-101 \\\n",
        "           --weights-path best_model.weights.h5 \\\n",
        "           --conv-blocks 4 --base-filters 64 --dropout 0.3 \\\n",
        "           --optimizer Adam --lr 0.001\n",
        "    7) 생성물 확인:\n",
        "       - results/            : 탐색 시 조합별 *.weights.h5 보관\n",
        "       - best_model.weights.h5, confusion_matrix.png : 루트에 생성\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9uf6_4k5mFTf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "006b7b24-c8b8-48b1-ae47-0940f909ae9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n프로그램 파이프라인 개요:\\n    1) 데이터: Kaggle Caltech-101 압축을 해제한 폴더에서 Faces_easy 클래스를 제외한다.\\n       (Caltech-101은 101개 객체 클래스 + background로 구성된 대표적인 분류 데이터셋)\\n    2) 입력: 모든 이미지를 128×128로 리사이즈하고 RGB를 0~1로 정규화한다. (Keras/TensorFlow 권장 전처리)\\n    3) 분할: 전체를 무작위 셔플 후 train/val/test = 8:1:1로 분할한다.\\n    4) 증강: dataset에 수평 뒤집기, 회전, 확대/축소, 대비 변화를 적용한다.\\n       (Keras 이미지 증강 레이어 사용; 추론 시에는 비활성)\\n    5) 탐색: 필요 시 하이퍼파라미터 탐색을 수행한다.\\n       - 구조 탐색: conv_blocks, base_filters 조합\\n       - 세부 탐색: dropout, optimizer, learning rate, epochs 조합\\n       - 조기종료(EarlyStopping)와 Plateau 시 학습률 감소(ReduceLROnPlateau)로 안정화\\n         (val_loss 모니터링, patience 설정)\\n       - 검증 성능(F1 포함)을 기준으로 최적 조합을 선택한다.\\n    6) 최종학습: 선택된 최적 하이퍼파라미터로 train/val 전체를 활용해 다시 학습하고\\n       가중치를 best_model.weights.h5로 저장한다. (가중치 형식)\\n    7) 평가: test 데이터로 예측을 수행하고 confusion_matrix.png와 매크로 F1 점수를 출력한다.\\n\\n파일 구조:\\n    - data_loader.py  : 데이터 로딩/전처리/분할(Faces_easy 제거, 8:1:1, cache/prefetch)\\n    - cnn_model.py    : 모델 빌드/증강/탐색/학습/평가 유틸\\n    - train.py        : 학습 실행 스크립트 (필요 시 --search로 하이퍼파라미터 탐색)\\n    - evaluate.py     : 평가 실행 스크립트 (학습 때의 구조/파라미터를 동일하게 지정해야함)\\n\\nColab 사용 절차:\\n    1) 로컬에서 Kaggle Caltech-101(archive.zip) 다운로드 후 Colab ‘파일’ 패널로 드래그 (/content 내로)\\n    2) 런타임 유형: GPU(T4) 설정\\n    3) 라이브러리 설치:\\n    !pip install tensorflow tensorflow-datasets tensorflow.keras scikit-learn matplotlib pathlib tqdm\\n    !pip install --upgrade tensorflow\\n    4) 데이터 압축 해제 후 경로 예: /content/caltech-101\\n    5) 학습 실행 예시:\\n       %cd ML_CNN\\n       !python train.py --data-dir /content/caltech-101 --augment\\n       # 하이퍼파라미터 탐색을 켜려면: --search\\n    6) 평가 실행 예시:\\n       !python evaluate.py --data-dir /content/caltech-101            --weights-path best_model.weights.h5            --conv-blocks 4 --base-filters 64 --dropout 0.3            --optimizer Adam --lr 0.001\\n    7) 생성물 확인:\\n       - results/            : 탐색 시 조합별 *.weights.h5 보관\\n       - best_model.weights.h5, confusion_matrix.png : 루트에 생성\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code run"
      ],
      "metadata": {
        "id": "2R9z5zWW_g7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python cnn_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS55h5S_4TZx",
        "outputId": "2b216876-cb69-463f-876f-c53f64957a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-31 07:21:57.701381: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756624917.733674    3185 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756624917.743633    3185 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756624917.766471    3185 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756624917.766510    3185 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756624917.766517    3185 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756624917.766523    3185 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-31 07:21:57.773139: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_loader.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zukWyc5-BiXc",
        "outputId": "7075fcbe-5461-4a60-d256-89e2c5f8907e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-31 07:27:40.757243: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756625260.788870    4672 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756625260.796245    4672 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756625260.818640    4672 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756625260.818679    4672 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756625260.818687    4672 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756625260.818694    4672 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data-dir /content/caltech-101 --augment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2Wz4mwqBnUx",
        "outputId": "e37d426f-50c7-4ff4-f711-dd811961be4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-31 07:33:05.723059: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756625585.741572    6059 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756625585.747137    6059 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756625585.761538    6059 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756625585.761564    6059 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756625585.761568    6059 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756625585.761573    6059 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Faces_easy 클래스 제거 완료\n",
            "Found 8709 files belonging to 101 classes.\n",
            "2025-08-31 07:33:10.815232: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1756625590.818330    6059 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "사전 정의된 하이퍼파라미터를 사용하여 학습을 진행합니다.\n",
            "사용할 최적 파라미터: {'conv_blocks': 4, 'base_filters': 64, 'dropout': 0.3, 'optimizer': 'Adam', 'lr': 0.001, 'epochs': 30}\n",
            "Epoch 1/30\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1756625612.529530    6101 service.cc:152] XLA service 0x7c97ec0c0680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1756625612.529579    6101 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1756625613.369760    6101 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2025-08-31 07:33:37.100697: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-08-31 07:33:37.270628: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "I0000 00:00:1756625621.605348    6101 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m217/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.1790 - loss: 4.15092025-08-31 07:34:09.170389: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-08-31 07:34:09.338032: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 182ms/step - accuracy: 0.1793 - loss: 4.1489 - val_accuracy: 0.0816 - val_loss: 5.0628 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.2491 - loss: 3.6680 - val_accuracy: 0.1897 - val_loss: 3.7796 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.2745 - loss: 3.4376 - val_accuracy: 0.2460 - val_loss: 3.5188 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.2901 - loss: 3.2735 - val_accuracy: 0.1874 - val_loss: 3.9893 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m217/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.3084 - loss: 3.1190\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.3085 - loss: 3.1185 - val_accuracy: 0.1609 - val_loss: 3.9300 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.3296 - loss: 2.9549 - val_accuracy: 0.2448 - val_loss: 3.4823 - learning_rate: 5.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.3417 - loss: 2.8584 - val_accuracy: 0.2448 - val_loss: 3.4050 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.3526 - loss: 2.7794 - val_accuracy: 0.2460 - val_loss: 3.5427 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m217/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3651 - loss: 2.7062\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.3652 - loss: 2.7059 - val_accuracy: 0.2333 - val_loss: 3.6203 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.3704 - loss: 2.6425 - val_accuracy: 0.2506 - val_loss: 3.3538 - learning_rate: 2.5000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.3916 - loss: 2.5848 - val_accuracy: 0.3218 - val_loss: 2.9547 - learning_rate: 2.5000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.3987 - loss: 2.5426 - val_accuracy: 0.3069 - val_loss: 3.0135 - learning_rate: 2.5000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m217/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4046 - loss: 2.4888\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.4047 - loss: 2.4885 - val_accuracy: 0.2943 - val_loss: 3.0497 - learning_rate: 2.5000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.4094 - loss: 2.4406 - val_accuracy: 0.2920 - val_loss: 3.1128 - learning_rate: 1.2500e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m217/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4178 - loss: 2.4027\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.4179 - loss: 2.4022 - val_accuracy: 0.2989 - val_loss: 3.0801 - learning_rate: 1.2500e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.4214 - loss: 2.3628 - val_accuracy: 0.3540 - val_loss: 2.8184 - learning_rate: 6.2500e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.4262 - loss: 2.3480 - val_accuracy: 0.3471 - val_loss: 2.8326 - learning_rate: 6.2500e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m217/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.4275 - loss: 2.3412\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.4277 - loss: 2.3408 - val_accuracy: 0.3517 - val_loss: 2.8350 - learning_rate: 6.2500e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.4368 - loss: 2.3190 - val_accuracy: 0.3736 - val_loss: 2.6911 - learning_rate: 3.1250e-05\n",
            "Epoch 20/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.4392 - loss: 2.2940 - val_accuracy: 0.3667 - val_loss: 2.6911 - learning_rate: 3.1250e-05\n",
            "Epoch 21/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.4391 - loss: 2.2986 - val_accuracy: 0.3920 - val_loss: 2.6181 - learning_rate: 3.1250e-05\n",
            "Epoch 22/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.4392 - loss: 2.2813 - val_accuracy: 0.3908 - val_loss: 2.6141 - learning_rate: 3.1250e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.4474 - loss: 2.2645 - val_accuracy: 0.3782 - val_loss: 2.6635 - learning_rate: 3.1250e-05\n",
            "Epoch 24/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.4412 - loss: 2.2539 - val_accuracy: 0.3874 - val_loss: 2.6012 - learning_rate: 3.1250e-05\n",
            "Epoch 25/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.4439 - loss: 2.2665 - val_accuracy: 0.3897 - val_loss: 2.5882 - learning_rate: 3.1250e-05\n",
            "Epoch 26/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.4493 - loss: 2.2436 - val_accuracy: 0.3897 - val_loss: 2.5999 - learning_rate: 3.1250e-05\n",
            "Epoch 27/30\n",
            "\u001b[1m217/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.4468 - loss: 2.2501\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.4469 - loss: 2.2496 - val_accuracy: 0.3874 - val_loss: 2.6236 - learning_rate: 3.1250e-05\n",
            "Epoch 28/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.4445 - loss: 2.2453 - val_accuracy: 0.4057 - val_loss: 2.5087 - learning_rate: 1.5625e-05\n",
            "Epoch 29/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.4519 - loss: 2.2132 - val_accuracy: 0.4126 - val_loss: 2.4901 - learning_rate: 1.5625e-05\n",
            "Epoch 30/30\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.4495 - loss: 2.2280 - val_accuracy: 0.4069 - val_loss: 2.5050 - learning_rate: 1.5625e-05\n",
            "모델 학습이 완료되었습니다. weights는 'best_model.weights.h5'에 저장됩니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py --data-dir /content/caltech-101 --weights-path best_model.weights.h5 \\\n",
        "                       --conv-blocks 4 --base-filters 64 --dropout 0.3 \\\n",
        "                       --optimizer Adam --lr 1e-3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtFDuByMFnez",
        "outputId": "0f19d806-d703-4438-c4ad-3c94187561e1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-31 07:52:36.675574: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756626756.694711   11403 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756626756.700613   11403 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756626756.715656   11403 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756626756.715691   11403 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756626756.715695   11403 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756626756.715699   11403 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Found 8709 files belonging to 101 classes.\n",
            "2025-08-31 07:52:41.666098: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1756626761.666256   11403 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 42 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "가중치를 best_model.weights.h5에서 로드했습니다.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1756626779.507514   11447 service.cc:152] XLA service 0x78d7ac605e40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1756626779.507554   11447 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1756626779.580760   11447 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1756626781.624661   11447 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "Confusion Matrix:\n",
            " [[25  1  0 ...  0  0  2]\n",
            " [ 1 53  0 ...  0  0  0]\n",
            " [ 0  0 16 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 1  0  0 ...  0  1  0]\n",
            " [ 0  0  0 ...  0  0  2]]\n",
            "F1 Score: 0.1382\n"
          ]
        }
      ]
    }
  ]
}